{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Biblioteca de Similaridade por cosseno https://pt.wikipedia.org/wiki/Similaridade_por_cosseno\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUANTIDADE_MINIMA_AVALIACOES_USUARIOS = 100\n",
    "QUANTIDADE_MINIMA_AVALIACOES_LIVROS = 20\n",
    "\n",
    "QUANTIDADE_RECOMENDACOES_COLABORATIVAS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_parquet(r\"backend\\data\\users.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paises = (\n",
    "    users_df[[\"COUNTRY\"]]\n",
    "    .drop_duplicates()\n",
    "    .reset_index()\n",
    "    .to_parquet(r\"backend\\data\\paises.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_parquet(r\"data\\users.parquet\")\n",
    "books_df = pd.read_parquet(r\"data\\books.parquet\")\n",
    "ratings_df = pd.read_parquet(r\"data\\ratings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntando a informação de avaliação com os detalhes do livro\n",
    "avaliacoes_com_info_df = ratings_df.merge(books_df, on=\"ISBN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(591896, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "considerar_usuarios_sr = (\n",
    "    avaliacoes_com_info_df.groupby(\"USER_ID\").count()[\"RATING\"]\n",
    "    > QUANTIDADE_MINIMA_AVALIACOES_USUARIOS\n",
    ")\n",
    "lista_usuarios_validos = considerar_usuarios_sr[considerar_usuarios_sr].index\n",
    "usuarios_filtrados_df = avaliacoes_com_info_df[\n",
    "    avaliacoes_com_info_df.USER_ID.isin(lista_usuarios_validos)\n",
    "]\n",
    "usuarios_filtrados_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181098, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "considerar_livros_sr = (\n",
    "    usuarios_filtrados_df.groupby(\"TITLE\").count()[\"RATING\"]\n",
    "    > QUANTIDADE_MINIMA_AVALIACOES_LIVROS\n",
    ")\n",
    "lista_livros_validos = considerar_livros_sr[considerar_livros_sr].index\n",
    "filtrados_df = usuarios_filtrados_df[\n",
    "    usuarios_filtrados_df.TITLE.isin(lista_livros_validos)\n",
    "]\n",
    "filtrados_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de tabela pivotada com os livros como linhas, os usuários como colunas e as avaliações como valores\n",
    "pivot_table_df = filtrados_df.pivot_table(\n",
    "    index=\"TITLE\", columns=\"USER_ID\", values=\"RATING\"\n",
    ")\n",
    "pivot_table_df.fillna(0, inplace=True)\n",
    "pivot_table_df.to_parquet(r\"data/pivot.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_df = pd.read_parquet(r\"data\\books.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table_df = pd.read_parquet(r\"data/pivot.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3810, 3810)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criação da matriz de similaridade por cosseno\n",
    "similaridade_cosseno = cosine_similarity(pivot_table_df)\n",
    "similaridade_cosseno.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def livros_recomendados_similaridade(\n",
    "    title: str, quant: int = QUANTIDADE_RECOMENDACOES_COLABORATIVAS\n",
    "):\n",
    "    books_df = pd.read_parquet(r\"data\\books.parquet\")\n",
    "    pivot_table_df = pd.read_parquet(r\"data\\pivot.parquet\")\n",
    "    similaridade_cosseno = cosine_similarity(pivot_table_df)\n",
    "\n",
    "    try:\n",
    "        if not title in pivot_table_df.index:\n",
    "            return {\n",
    "                \"Success\": False,\n",
    "                \"Message\": f'O livro \"{title}\" não consta em nossa lista.',\n",
    "            }\n",
    "\n",
    "        index = np.where(pivot_table_df.index == title)[0][0]\n",
    "\n",
    "        # Lista os items similares ao informado (começando do segundo índice para não pegar o próprio livro)\n",
    "        similar_items = sorted(\n",
    "            enumerate(similaridade_cosseno[index]), key=lambda x: x[1], reverse=True\n",
    "        )[1 : quant + 1]\n",
    "\n",
    "        data = []\n",
    "        for i in similar_items:\n",
    "            item = {}\n",
    "            temp_df = books_df[books_df[\"TITLE\"] == pivot_table_df.index[i[0]]]\n",
    "            item[\"TITLE\"] = list(temp_df.drop_duplicates(\"TITLE\")[\"TITLE\"].values)[0]\n",
    "            item[\"AUTHOR\"] = list(temp_df.drop_duplicates(\"TITLE\")[\"AUTHOR\"].values)[0]\n",
    "            item[\"IMAGE_S\"] = list(temp_df.drop_duplicates(\"TITLE\")[\"IMAGE_S\"].values)[\n",
    "                0\n",
    "            ]\n",
    "            item[\"IMAGE_M\"] = list(temp_df.drop_duplicates(\"TITLE\")[\"IMAGE_M\"].values)[\n",
    "                0\n",
    "            ]\n",
    "            item[\"IMAGE_L\"] = list(temp_df.drop_duplicates(\"TITLE\")[\"IMAGE_L\"].values)[\n",
    "                0\n",
    "            ]\n",
    "            data.append(item)\n",
    "\n",
    "        return {\"success\": True, \"livros\": data}\n",
    "    except Exception as ex:\n",
    "        return {\"success\": False, \"Message\": ex}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Success': True,\n",
       " 'livros': [{'TITLE': 'Danger',\n",
       "   'AUTHOR': 'Dick Francis',\n",
       "   'IMAGE_S': 'http://images.amazon.com/images/P/0449202631.01.THUMBZZZ.jpg',\n",
       "   'IMAGE_M': 'http://images.amazon.com/images/P/0449202631.01.MZZZZZZZ.jpg',\n",
       "   'IMAGE_L': 'http://images.amazon.com/images/P/0449202631.01.LZZZZZZZ.jpg'},\n",
       "  {'TITLE': 'A Season in Purgatory',\n",
       "   'AUTHOR': 'Dominick Dunne',\n",
       "   'IMAGE_S': 'http://images.amazon.com/images/P/0345430557.01.THUMBZZZ.jpg',\n",
       "   'IMAGE_M': 'http://images.amazon.com/images/P/0345430557.01.MZZZZZZZ.jpg',\n",
       "   'IMAGE_L': 'http://images.amazon.com/images/P/0345430557.01.LZZZZZZZ.jpg'},\n",
       "  {'TITLE': 'Die for Love',\n",
       "   'AUTHOR': 'Elizabeth Peters',\n",
       "   'IMAGE_S': 'http://images.amazon.com/images/P/0380731169.01.THUMBZZZ.jpg',\n",
       "   'IMAGE_M': 'http://images.amazon.com/images/P/0380731169.01.MZZZZZZZ.jpg',\n",
       "   'IMAGE_L': 'http://images.amazon.com/images/P/0380731169.01.LZZZZZZZ.jpg'},\n",
       "  {'TITLE': 'Decider',\n",
       "   'AUTHOR': 'Dick Francis',\n",
       "   'IMAGE_S': 'http://images.amazon.com/images/P/0515116173.01.THUMBZZZ.jpg',\n",
       "   'IMAGE_M': 'http://images.amazon.com/images/P/0515116173.01.MZZZZZZZ.jpg',\n",
       "   'IMAGE_L': 'http://images.amazon.com/images/P/0515116173.01.LZZZZZZZ.jpg'},\n",
       "  {'TITLE': \"Farriers' Lane\",\n",
       "   'AUTHOR': 'Anne Perry',\n",
       "   'IMAGE_S': 'http://images.amazon.com/images/P/0449219615.01.THUMBZZZ.jpg',\n",
       "   'IMAGE_M': 'http://images.amazon.com/images/P/0449219615.01.MZZZZZZZ.jpg',\n",
       "   'IMAGE_L': 'http://images.amazon.com/images/P/0449219615.01.LZZZZZZZ.jpg'}]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "livros_recomendados_similaridade(\"10 Lb. Penalty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
